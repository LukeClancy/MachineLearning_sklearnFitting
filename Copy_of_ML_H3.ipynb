{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ML.H3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukeClancy/sklearnFitting/blob/master/Copy_of_ML_H3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tMEdi-WyI5D3",
        "colab_type": "code",
        "outputId": "ae73129a-1c56-4842-ade9-61f972dfe141",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pylab\n",
        "import sklearn.linear_model as sklm\n",
        "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
        "import sklearn.naive_bayes as sknaive\n",
        "from sklearn import tree\n",
        "from google.colab import files\n",
        "\n",
        "def easyFormat(X, testStart, testLen):\n",
        "  #Training partitioning\n",
        "  train = X[:testStart] + X[(testStart + testLen):] \n",
        "  trainingData = [a[1:] for a in train]\n",
        "  #print(str(trainingData))\n",
        "  trainingTargets = [a[0] for a in train]\n",
        "  #Testing partitioning\n",
        "  test = X[testStart:(testStart + testLen)]\n",
        "  testData = [a[1:] for a in test]\n",
        "  testTargets = [a[0] for a in test]\n",
        "  return {'trainingData':trainingData, 'trainingTargets':trainingTargets, 'testData':testData, 'testTargets':testTargets}\n",
        "\n",
        "def MonkTree(X):\n",
        "  #train data\n",
        "  decTree = tree.DecisionTreeClassifier(max_depth=10)\n",
        "  decTree = decTree.fit(X['trainingData'], X['trainingTargets'])\n",
        "  #end train\n",
        "  \n",
        "  #test data\n",
        "  predictions = decTree.predict(X['testData'])\n",
        "  match = 0.0\n",
        "  miss = 0.0\n",
        "  stop = len(predictions)\n",
        "  predN = 0\n",
        "  while predN < stop:\n",
        "    if predictions[predN] == X['testTargets'][predN]:\n",
        "      match += 1\n",
        "    else:\n",
        "      miss += 1\n",
        "    predN = predN + 1\n",
        "  #print(\"match: \" + str(match) + \", miss: \" + str(miss))\n",
        "  #return test results\n",
        "  return match / (match + miss)\n",
        "\n",
        "def MonkNB(X):\n",
        "  NB = sknaive.GaussianNB()\n",
        "  NB.fit(X['trainingData'], X['trainingTargets'])\n",
        "  predictions = NB.predict(X['testData'])\n",
        "  match = 0.0\n",
        "  miss = 0.0\n",
        "  stop = len(predictions)\n",
        "  predN = 0\n",
        "  while predN < stop:\n",
        "    if predictions[predN] == X['testTargets'][predN]:\n",
        "      match += 1\n",
        "    else:\n",
        "      miss += 1\n",
        "    predN = predN + 1\n",
        "  #print(\"match: \" + str(match) + \", miss: \" + str(miss))\n",
        "  #return test results\n",
        "  return match / (match + miss)\n",
        "\n",
        "def MonkNN(X):\n",
        "  NNModel = NearestCentroid()\n",
        "  NNModel.fit(X['trainingData'], X['trainingTargets'])\n",
        "  \n",
        "    #test data\n",
        "  predictions = NNModel.predict(X['testData'])\n",
        "  match = 0.0\n",
        "  miss = 0.0\n",
        "  stop = len(predictions)\n",
        "  predN = 0\n",
        "  while predN < stop:\n",
        "    if predictions[predN] == X['testTargets'][predN]:\n",
        "      match += 1\n",
        "    else:\n",
        "      miss += 1\n",
        "    predN = predN + 1\n",
        "  #print(\"match: \" + str(match) + \", miss: \" + str(miss))\n",
        "  #return test results\n",
        "  return match / (match + miss)\n",
        "\n",
        "def MonkPerceptron(X):\n",
        "  '''\n",
        "  where X is data in the form of library after put through easyFormat function\n",
        "  '''\n",
        "  #train data\n",
        "  perceptronModel = sklm.Perceptron(max_iter=100, shuffle=True, verbose=0, early_stopping=True)\n",
        "  perceptronModel.fit(X['trainingData'], X['trainingTargets'])\n",
        "  #train end\n",
        "  \n",
        "  #test data\n",
        "  predictions = perceptronModel.predict(X['testData'])\n",
        "  match = 0.0\n",
        "  miss = 0.0\n",
        "  stop = len(predictions)\n",
        "  predN = 0\n",
        "  while predN < stop:\n",
        "    if predictions[predN] == X['testTargets'][predN]:\n",
        "      match += 1\n",
        "    else:\n",
        "      miss += 1\n",
        "    predN = predN + 1\n",
        "  #print(\"match: \" + str(match) + \", miss: \" + str(miss))\n",
        "  #return test results\n",
        "  return match / (match + miss)\n",
        "\n",
        "def fold(X, numFolds, fun):\n",
        "  grpLen = len(X) / numFolds\n",
        "  lst = []\n",
        "  #print('perceptron accuracy: ' + str(MonkPerceptron(X)))\n",
        "  for a in range(numFolds):\n",
        "    startIndex = a*grpLen\n",
        "    #print('cycle: ' + str(a) + \", strtIndex: \" + str(startIndex) + \", grpLen: \" + str(grpLen))\n",
        "    formX = easyFormat(X, a*grpLen, grpLen)\n",
        "    lst.append(fun(formX))\n",
        "  average = 0.0\n",
        "  for a in lst:\n",
        "    average += a/len(lst)\n",
        "  return average\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  #----------------READFILE-----------------------------------------------------\n",
        "  print('available files:')\n",
        "  !ls\n",
        "  _files = files.upload()\n",
        "  print('files after upload:')\n",
        "  !ls\n",
        "  print('__________________')\n",
        "  if len(_files.keys()) == 1: #entered a file\n",
        "    print('opening ' + str(_files.keys()[0]))\n",
        "    myFile = open(str(_files.keys()[0]), \"r\")\n",
        "  else: #using pre-existing file, or had a spasm attack and uploaded like, 5.\n",
        "    fileName = input(\"please enter chosen filename, it doesnt like dots so use \\\"s \")\n",
        "    myFile = open(fileName, \"r\")\n",
        "  line = myFile.readline()\n",
        "  print('__________________')\n",
        "  print('past file selection, first line:' + line)\n",
        "  X = []\n",
        "  while line and line != \"\":\n",
        "    dat = line.split(',')\n",
        "    for a in range(len(dat)):\n",
        "      dat[a] = int(dat[a])\n",
        "    X.append(dat)\n",
        "    line = myFile.readline()\n",
        "  #------------------END READ---------------------------------------------------\n",
        "  worst = 1\n",
        "  best = 0\n",
        "  av = fold(X, 3, MonkPerceptron)\n",
        "  print(\"average accuracy perceptron 3-fold: \" + str(av))\n",
        "  av = fold(X, len(X), MonkPerceptron)\n",
        "  print(\"average accuracy perceptron Leave One Out: \" + str(av))\n",
        "  \n",
        "  \n",
        "  av = fold(X, 3, MonkTree)\n",
        "  print(\"average accuracy Decision Tree 3-fold: \" + str(av))\n",
        "  av = fold(X, len(X), MonkTree)\n",
        "  print(\"average accuracy Decision Tree Leave One Out: \" + str(av))\n",
        "  \n",
        "  av = fold(X, 3, MonkNB)\n",
        "  print(\"average accuracy Naive Bayes 3-fold: \" + str(av))\n",
        "  av = fold(X, len(X), MonkNB)\n",
        "  print(\"average accuracy Naive Bayes Leave One Out: \" + str(av))\n",
        "  \n",
        "  av = fold(X, 3, MonkNN)\n",
        "  print(\"average accuracy NN centroid 3-fold: \" + str(av))\n",
        "  av = fold(X, len(X), MonkNN)\n",
        "  print(\"average accuracy NN centroid Leave One Out: \" + str(av))\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "available files:\n",
            "monks-1.csv  monks-2.csv  monks-3.csv  sample_data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a50c76e4-3a5c-4f0f-9939-6aebf7265e6f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a50c76e4-3a5c-4f0f-9939-6aebf7265e6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "files after upload:\n",
            "monks-1.csv  monks-2.csv  monks-3.csv  sample_data\n",
            "__________________\n",
            "please enter chosen filename, it doesnt like dots so use \"s 'monks-1.csv'\n",
            "__________________\n",
            "past file selection, first line:1,1,1,1,1,3,1\n",
            "\n",
            "average accuracy perceptron 3-fold: 0.477477477477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HUo4028plKBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luke Clancy\n",
        "\n",
        "11432090\n",
        "\n",
        "HA #3\n",
        "\n",
        "\n",
        "_______________________________________________________________________________________\n",
        "\n",
        "#1.\n",
        "\n",
        "100 pos, 100 neg\n",
        "d features\n",
        "\n",
        "-> Majority classifier -> leave one out cross validation\n",
        "\n",
        "If leave one out cross validation is used, there will be one hundred false positives and one hundred false negatives. This is as for each case leave one out will leave out either a positive or negative, skewing the majority classifier.\n",
        "\n",
        "#2\n",
        "Perceptron Model:\n",
        "\n",
        "x1, w1\\\n",
        "\n",
        "        \\ \n",
        "\n",
        "\n",
        "x2, w2-----> ( ![alt text](https://drive.google.com/uc?id=19rLMsrU6WKMnVCoy4-EdHCDCs4_whKRt) + b )     - >       if a == 0{Ypred = -1} else{Ypred = a/|a| }\n",
        "     \n",
        "        /\n",
        "  \n",
        "x3, w3 /\n",
        "\n",
        "Iterations:\n",
        "\n",
        "1. w0 = [0, 0, 0, 0], x0 = [1, 0, 0, 0]\n",
        "\n",
        "  a = 0, Ypred=-1, Y=-1. Match, dont change w\n",
        "\n",
        "2. w1 = [0, 0, 0, 0], x1=[1, 0, 0, 1]\n",
        "\n",
        "  a = 0, Ypred=-1, Y=1. Mismatch, increase w\n",
        "\n",
        "3. W2 = w1 + x1*Y  = [1, 0, 0, 1], X2 = [1, 0, 1, 0]\n",
        "\n",
        "  a = 1, Ypred=1, Y=1. Match, dont change W\n",
        "\n",
        "\n",
        "as b = 1 and Y=1 for the rest of the values on this cycle, they will all pass and W will not change.\n",
        "\n",
        "On the second cycle, W will end with W=[1, 0, 1, 1]\n",
        "\n",
        "On the third cycle, W will end with W=[1, 1, 1, 1]\n",
        "\n",
        "The data will be fit on the  fourth with W=[0, 1, 1, 1] (b is the 0)\n",
        "\n",
        "#3\n",
        "\n",
        "code above. Each better at diffrent databases. The Monk test shows that each is valuable in their own way and there is no \"best\".\n"
      ]
    },
    {
      "metadata": {
        "id": "qh3LZ46YI57Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Homework Assignment #3**\n",
        "\n",
        "Assigned: January 29, 2019\n",
        "\n",
        "Due: February 7, 2019\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This assignment consists of four questions that require a short answer and one that requires you to generate some Python code. You can enter your answers and your code directly in a Colaboratory notebook and upload the **shareable** link for the your notebook as your homework submission.\n",
        "\n",
        "---\n",
        "\n",
        "#1.\n",
        "\n",
        "(8 points) Consider a data set you want to analyze that contains\n",
        "200 data points, half positive examples and half negative examples.\n",
        "Each example is described by *d* features.  To predict the data labels\n",
        "you use a majority classifier that outputs the most common class from\n",
        "the training data, resolving ties randomly.  What accuracy can you expect\n",
        "from the majority classifier if you evaluate it using leave-one-out\n",
        "cross validation?\n",
        "\n",
        "#2.\n",
        "\n",
        "(10 points) Draw a perceptron that could be used to compute the logical or function, a subset of whose inputs and outputs are shown below.\n",
        "\n",
        "$x_1$ | $x_2$ | $x_3$ | $y$\n",
        "--- | --- | --- | ---\n",
        "0 | 0 | 0 | -1\n",
        "0 | 0 | 1 | 1\n",
        "0 | 1 | 0 | 1\n",
        "0 | 1 | 1 | 1\n",
        "1 | 0 | 0 | 1\n",
        "\n",
        "Assuming that the weights are bias are initialized to 0, show how these values will be updated based on one iteration of perceptron training with the input and output values given here.\n",
        "\n",
        "#3.\n",
        "\n",
        "(80 points) For this problem you will use the sklearn libraries to compare the performance of alternative classifiers. Run your code on the three monks datasets found at  https://drive.google.com/open?id=16Xf4j3j4B4amVzTeEEHUg1XvhFTLma2n, https://drive.google.com/open?id=1ucRViqlISHYv-T2v0xK15Tcfk4dgkw1F, and https://drive.google.com/open?id=15ccf4SG5Vlb_O7v6zXxzxpBXbiJ1UcFV. A description of the datasets can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/monks-problems/monks.names, we have modified the datasets to make them slightly easier to use. Note, however, in these datasets the class value is the *first* feature of each line.\n",
        "\n",
        "Test the following classifiers:\n",
        "\n",
        "* perceptron with a maximum of 50 iterations\n",
        "* decision tree with a maximum depth of 10\n",
        "* knn with k = 3\n",
        "* naive Bayes (use the Gaussian implementation)\n",
        "\n",
        "For each classifier, report the following:\n",
        "\n",
        "\n",
        "*   Accuracy using 3-fold cross validation\n",
        "*   Accuracy using leave-one-out testing\n",
        "\n",
        "Use your findings to answer the following questions:\n",
        "\n",
        "* Which classifier performs the best for each dataset and which performs worst?\n",
        "* Given the description of the datasets, do you have an explanation for which classifiers perform best and worst?\n",
        "\n",
        "Finally, use the paired t test function found in the scipy library to answer the question:\n",
        "\n",
        "* Is the difference between the best-performing classifier and the worst-performing classifier statistically significant? Why or why not?"
      ]
    }
  ]
}